{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e7b4c1-4b3d-4ad1-8421-6c37febe9ac2",
   "metadata": {},
   "source": [
    "# Tarefa 01: Compreendendo o Bagging (Bootstrap Aggregating)\n",
    "\n",
    "## 1. O Passo a Passo do Bagging\n",
    "\n",
    "O processo de construção de um modelo de **Ensemble** via Bagging segue um fluxo lógico dividido em três etapas fundamentais:\n",
    "\n",
    "* **Criação dos Subconjuntos (Bootstrap):** A partir do banco de dados original, são criados múltiplos subconjuntos de dados. Este processo ocorre por meio de sorteios aleatórios de linhas **com reposição**, o que significa que uma mesma observação pode aparecer repetidas vezes em um mesmo subconjunto.\n",
    "* **Treinamento em Paralelo (Modelagem):** Define-se um algoritmo base (geralmente uma **Árvore de Decisão**) que será treinado de forma independente para cada subconjunto gerado no passo anterior. Como os modelos são processados em paralelo, eles não interagem entre si durante a fase de aprendizagem.\n",
    "* **Votação ou Média (Agregação):** Para consolidar o resultado final das múltiplas predições:\n",
    "    * **Classificação:** Utiliza-se a votação majoritária (a classe mais frequente entre os modelos vence).\n",
    "    * **Regressão:** Calcula-se a média aritmética simples das previsões de todos os modelos.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Explicação Conceitual\n",
    "\n",
    "O **Bagging** funciona como uma proteção robusta contra erros individuais e ruídos nos dados. Em vez de confiar em um único modelo que pode sofrer de *overfitting* (ajuste excessivo ao ruído), utilizamos a força do conjunto.\n",
    "\n",
    "Como cada modelo é treinado com uma amostra diferente (**Bootstrap**), erros específicos de uma fatia de dados não comprometem o resultado final, pois são filtrados pelo consenso no momento da **Agregação**. Em termos estatísticos, essa técnica é extremamente eficaz para reduzir a **variância**, gerando uma análise muito mais estável e confiável, especialmente em mercados voláteis como o financeiro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89434ac1-85c4-4c17-b2d7-05655b6db562",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4373dc-256b-44fa-b040-2fcf136f4225",
   "metadata": {},
   "source": [
    "# 3. Implementação em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849babb-b7e8-49d1-831a-ee8411762041",
   "metadata": {},
   "source": [
    "## Vamos usar o scikit-learn para criar um modelo de Bagging que tenta classificar se um ativo terá retorno positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc438e91-3bab-4dd5-86a0-3436e574e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50ed891-02f6-43af-b5aa-43ddf4c2138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Bagging: 48.67%\n"
     ]
    }
   ],
   "source": [
    "# 1. Preparando os dados \n",
    "# Vamos supor que queremos prever se amanhã o retorno é positivo (1) ou negativo (0)\n",
    "df_ret = pd.read_csv('dados_ativos_fechamento.csv', index_col=0)\n",
    "df_ret = df_ret.pct_change().dropna()\n",
    "\n",
    "# Prever direção da VALE3 com base no retorno de hoje\n",
    "X = df_ret[['ITUB4.SA', 'PETR4.SA']] # Variáveis explicativas\n",
    "y = (df_ret['VALE3.SA'] > 0).astype(int) # Alvo: 1 se subiu, 0 se caiu\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 2. O BAGGING na prática\n",
    "# Criamos 50 Árvores de Decisão independentes\n",
    "modelo_bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=50, \n",
    "    max_samples=0.8, # Cada modelo vê 80% dos dados (Bootstrap)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Treinamento\n",
    "modelo_bagging.fit(X_train, y_train)\n",
    "\n",
    "# 4. Avaliação\n",
    "previsoes = modelo_bagging.predict(X_test)\n",
    "print(f\"Acurácia do modelo Bagging: {accuracy_score(y_test, previsoes):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07024fd1-7203-4d63-bd1c-698e5e02e184",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
